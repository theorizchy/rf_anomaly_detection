{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set TF_GPU_ALLOCATOR environment variable\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner import HyperParameters\n",
    "\n",
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back X_train, X_test, y_train, and y_test\n",
    "X_train = np.loadtxt('train_data/X_train.txt')\n",
    "X_test = np.loadtxt('train_data/X_test.txt')\n",
    "y_train = np.loadtxt('train_data/y_train.txt')\n",
    "y_test = np.loadtxt('train_data/y_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN for Feature Extraction:\n",
    "\n",
    "- Start with a CNN to extract features from the power measurements at different frequencies. Since the frequency information is spatially related, we can treat it as an image where each frequency bin is a pixel. Design the CNN architecture to have convolutional layers to capture local patterns in the frequency domain. The output of the CNN will be a feature map capturing important frequency-domain features.\n",
    "\n",
    "RNN for Temporal Modeling:\n",
    "- Feed the output of the CNN into an RNN (such as LSTM or GRU) to model temporal dependencies in the time-series data.\n",
    "- The RNN will capture the temporal dynamics and sequential patterns in the power measurements over time.\n",
    "\n",
    "This architecture allows the model to learn both frequency-domain features and temporal dependencies simultaneously.\n",
    "\n",
    "Hybrid CNN-RNN Architecture:\n",
    "- We can design a hybrid architecture where the CNN and RNN parts are connected sequentially. The CNN part processes the input frequency data to extract features, and the output is then fed into the RNN for temporal modeling.\n",
    "- This architecture allows for both spatial (frequency) and temporal information to be captured effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1637, 76802)\n",
      "(410, 76802)\n",
      "(1637,)\n",
      "(410,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to 3D for CNN input (samples, time steps, features)\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "y_train_reshaped = y_train.reshape((-1, 1))\n",
    "y_test_reshaped = y_test.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1637, 76802, 1)\n",
      "(410, 76802, 1)\n",
      "(1637, 1)\n",
      "(410, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_reshaped.shape)\n",
    "print(X_test_reshaped.shape)\n",
    "print(y_train_reshaped.shape)\n",
    "print(y_test_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am building a hybrid CNN and RNN model, taking power measurement of RF activity from 0 to 6.0 GHz to determine whether a camera is being turned on or off, based on its electromagnetic emanation. I have the raw data splitted accoring to these variables: X_train, X_test, y_trarin, y_test are numpy array of dimension (1637, 76802), (410, 76802), (1637,), (410,) respectively, where the row is capture data taken every seconds, and columns are power measurement in dBm (watts) from 0 to 6.0 GHz frequency taken by spectrum analyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN-RNN hybrid model\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # CNN layers for feature extraction\n",
    "    model.add(keras.layers.Conv1D(filters=hp.Int('conv_filters', min_value=64, max_value=128, step=16),\n",
    "                                   kernel_size=hp.Int('conv_kernel', min_value=5, max_value=10, step=1),\n",
    "                                   activation='relu',\n",
    "                                   input_shape=(X_train_reshaped.shape[1], 1)))\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(keras.layers.Dropout(rate=hp.Float('dropout_cnn', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # LSTM layers for temporal modeling\n",
    "    model.add(keras.layers.LSTM(units=hp.Int('lstm_units', min_value=64, max_value=128, step=16),\n",
    "                                return_sequences=True))\n",
    "    model.add(keras.layers.Dropout(rate=hp.Float('dropout_rnn', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a keras tuner for random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras Tuner RandomSearch\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    directory='keras_tuning',\n",
    "    project_name='cnn_rnn_tuner')\n",
    "\n",
    "# Perform hyperparameter search\n",
    "tuner.search(X_train_reshaped, y_train_reshaped,\n",
    "             epochs=3,\n",
    "             validation_data=(X_test_reshaped, y_test_reshaped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "# Save the Keras model to an HDF5 file\n",
    "model_file_path = os.path.join('models', 'hybrid_cnn_rnn.h5')\n",
    "best_model.save(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best hyperparameters\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model\n",
    "evaluation = best_model.evaluate(X_test, y_test)\n",
    "# Print evaluation results\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in best_model.layers:\n",
    "    print('Input Layers:')\n",
    "    print(layer.input)\n",
    "    print('Output Layers:')\n",
    "    print(layer.output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
