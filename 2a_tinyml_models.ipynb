{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply TinyML techniques to reduce model sizes\n",
    "\n",
    "Optimize the model using TensorFlow Lite and quantization. Convert the trained model to the TensorFlow Lite format and then apply quantization to reduce its size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back X_train, X_test, y_train, and y_test\n",
    "X_train = np.loadtxt('train_data/X_train_t10.txt')\n",
    "X_test = np.loadtxt('train_data/X_test_t10.txt')\n",
    "y_train = np.loadtxt('train_data/y_train_t10.txt')\n",
    "y_test = np.loadtxt('train_data/y_test_t10.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/scaler.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler for later use in real-time data normalization\n",
    "joblib.dump(scaler, 'models/scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Deep Neural-Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    # tf.keras.layers.Dropout(0.5),  # Add dropout for regularization\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',  # Change optimizer to Adam\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 1s 6ms/step - loss: 0.0796 - accuracy: 0.9672 - val_loss: 6.5707e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9945 - val_loss: 3.2789e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9945 - val_loss: 0.0026 - val_accuracy: 0.9969\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0134 - val_accuracy: 0.9969\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 3.9161e-06 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9969\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 6.6729e-07 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9969\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 3.7128e-07 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c25da5580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, \n",
    "          epochs=100, \n",
    "          batch_size=32, \n",
    "          validation_split=0.2, \n",
    "          class_weight=class_weights,\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 548us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00       199\n",
      "         1.0       1.00      1.00      1.00       201\n",
      "\n",
      "    accuracy                           1.00       400\n",
      "   macro avg       1.00      1.00      1.00       400\n",
      "weighted avg       1.00      1.00      1.00       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\theor\\AppData\\Local\\Temp\\tmp9d29vdet\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert and save the TensorFlow model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the TensorFlow Lite model to a file\n",
    "model_file_path = os.path.join('models', 'model.tflite')\n",
    "with open(model_file_path, \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is 6881700 bytes\n"
     ]
    }
   ],
   "source": [
    "model_size = os.path.getsize(model_file_path)\n",
    "print(\"Model is %d bytes\" % model_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\theor\\AppData\\Local\\Temp\\tmpjqehzo7k\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\theor\\AppData\\Local\\Temp\\tmpjqehzo7k\\assets\n"
     ]
    }
   ],
   "source": [
    "# Set optimizations (quantization)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Convert the model\n",
    "tflite_model_optimize = converter.convert()\n",
    "\n",
    "model_file_path = os.path.join('models', 'optimize.tflite')\n",
    "with open(model_file_path, \"wb\") as f:\n",
    "    f.write(tflite_model_optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Model is 1723976 bytes\n"
     ]
    }
   ],
   "source": [
    "optimized_model_size = os.path.getsize(model_file_path)\n",
    "print(\"Optimized Model is %d bytes\" % optimized_model_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the optimized TensorFlow Lite model\n",
    "optimized_model_path = 'models/optimize.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=optimized_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Prepare input data\n",
    "input_data = X_test_scaled[0:1].astype(np.float32)  # Take the first sample from X_test_scaled\n",
    "\n",
    "# Set input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# Convert output to binary predictions\n",
    "predictions_binary = (output_data > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the predictions\n",
    "print(classification_report(y_test[0:1], predictions_binary))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
