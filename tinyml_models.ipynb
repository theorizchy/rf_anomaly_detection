{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply TinyML techniques to reduce model sizes\n",
    "\n",
    "Optimize the model using TensorFlow Lite and quantization. Convert the trained model to the TensorFlow Lite format and then apply quantization to reduce its size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back X_train, X_test, y_train, and y_test\n",
    "X_train = np.loadtxt('train_data/X_train.txt')\n",
    "X_test = np.loadtxt('train_data/X_test.txt')\n",
    "y_train = np.loadtxt('train_data/y_train.txt')\n",
    "y_test = np.loadtxt('train_data/y_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Deep Neural-Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection and Training\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.0881 - accuracy: 0.9673 - val_loss: 1.0558e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 2.6404e-05 - accuracy: 1.0000 - val_loss: 9.8665e-06 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 5.9485e-14 - accuracy: 1.0000 - val_loss: 6.3569e-06 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 6.0204e-14 - accuracy: 1.0000 - val_loss: 6.0123e-06 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 6.5347e-14 - accuracy: 1.0000 - val_loss: 5.9704e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 6.5519e-14 - accuracy: 1.0000 - val_loss: 5.9654e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 6.5544e-14 - accuracy: 1.0000 - val_loss: 5.9649e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 6.5547e-14 - accuracy: 1.0000 - val_loss: 5.9649e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 6.5547e-14 - accuracy: 1.0000 - val_loss: 5.9649e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 6.5547e-14 - accuracy: 1.0000 - val_loss: 5.9649e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x15629dbbeb0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predictions_binary = (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       204\n",
      "         1.0       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00       211\n",
      "   macro avg       1.00      1.00      1.00       211\n",
      "weighted avg       1.00      1.00      1.00       211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\theor\\AppData\\Local\\Temp\\tmp3tifeuej\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\theor\\AppData\\Local\\Temp\\tmp3tifeuej\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert and save the TensorFlow model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the TensorFlow Lite model to a file\n",
    "model_file_path = os.path.join('models', 'dnn_model.tflite')\n",
    "with open(model_file_path, \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\theor\\AppData\\Local\\Temp\\tmpq9kkh8cw\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\theor\\AppData\\Local\\Temp\\tmpq9kkh8cw\\assets\n"
     ]
    }
   ],
   "source": [
    "# Set optimizations (quantization)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Convert the model\n",
    "tflite_model_optimize = converter.convert()\n",
    "\n",
    "model_file_path = os.path.join('models', 'model_optimize.tflite')\n",
    "with open(model_file_path, \"wb\") as f:\n",
    "    f.write(tflite_model_optimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the optimized TensorFlow Lite model\n",
    "optimized_model_path = 'models/model_optimize.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=optimized_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Prepare input data\n",
    "input_data = X_test_scaled[0:1].astype(np.float32)  # Take the first sample from X_test_scaled\n",
    "\n",
    "# Set input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# Convert output to binary predictions\n",
    "predictions_binary = (output_data > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the predictions\n",
    "print(classification_report(y_test[0:1], predictions_binary))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
